{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a763fd67",
   "metadata": {},
   "source": [
    "Extensiones usadas en el Proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90028309",
   "metadata": {},
   "source": [
    "Extensiones usadas para el Desarrollo de los Algoritmos y Muestra de Resultados:\n",
    "\n",
    "1- numpy: procesamiento de los cálculos matriciales y vectoriales.\n",
    "\n",
    "2- matplotlib: visualización gráficas y tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc4dac",
   "metadata": {},
   "source": [
    "Funciones que calculan los valores de:\n",
    "\n",
    "1- Función Objetivo\n",
    "2- Vector Gradiente\n",
    "3- Matriz Hessiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b470b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función Objetivo\n",
    "def f(x):\n",
    "    return (np.exp(x[0]) + 1)*(x[1]**2 + 1) - np.sin(x[0] + x[1]**2) - x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5db11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Gradiente\n",
    "def grad_f(x):\n",
    "    \n",
    "    df_dx = np.exp(x[0])*(x[1]**2 + 1) - np.cos(x[0] + x[1]**2) - 1\n",
    "    df_dy = 2*x[1]*(np.exp(x[0]) + 1) - 2*x[1]*np.cos(x[0] + x[1]**2)\n",
    "    return np.array([df_dx, df_dy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ae073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hessiano \n",
    "def hess_f(x):\n",
    "    h11 = np.exp(x[0])*(x[1]**2 + 1) + np.sin(x[0] + x[1]**2)\n",
    "    h22 = 2*(np.exp(x[0]) + 1) - 2*np.cos(x[0] + x[1]**2) + 4*x[1]**2*np.sin(x[0] + x[1]**2)\n",
    "    h12 = 2*x[1]*np.exp(x[0]) + 2*x[1]*np.sin(x[0] + x[1]**2)\n",
    "    return np.array([[h11, h12], [h12, h22]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d609996",
   "metadata": {},
   "source": [
    "Desarrollo Algoritmo Región de COnfianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c85c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método de Región de Confianza\n",
    "def trust_region_method(x0, grad_f, hess_f, delta0=1.0, eta=0.15, tol=1e-6, max_iter=1000):\n",
    "    \n",
    "    # x0: punto inicial\n",
    "    # grad_f: función que calcula el gradiente\n",
    "    # hess_f: función que calcula el Hessiano\n",
    "    # delta0: radio inicial de la región de confianza\n",
    "    # eta: umbral para aceptar el paso (0 < eta < 1)\n",
    "    # tol: tolerancia para criterio de parada\n",
    "    # max_iter: número máximo de iteraciones\n",
    "\n",
    "    x = np.array(x0, dtype=float)\n",
    "    delta = delta0 #radio region de confianza\n",
    "\n",
    "    history = [x.copy()] #almacenar historial de puntos\n",
    "\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # 1- Calcular gradiente y Hessiana\n",
    "        g = grad_f(x)\n",
    "        B = hess_f(x)\n",
    "\n",
    "        if np.linalg.norm(g) < tol: # verificar gradiente es suficientemente pequeño\n",
    "            break\n",
    "        # 2- Resolver el subproblema Region COnfianza\n",
    "        try:\n",
    "            # Intentar calcular paso de Newton\n",
    "            p_newton = -np.linalg.solve(B, g)\n",
    "\n",
    "            # Verificar paso de Newton está dentro de la Region de COnfianza\n",
    "            if np.linalg.norm(p_newton) <= delta:\n",
    "                p = p_newton\n",
    "            else:\n",
    "                #calcular paso Cauchy => dirección máximo descenso\n",
    "                p_cauchy = - (np.dot(g, g) / (np.dot(g, np.dot(B, g)) + 1e-12)) * g \n",
    "\n",
    "                # Verificar si paso Cauchy dentro de la region de Confiaza\n",
    "                if np.linalg.norm(p_cauchy) > delta:\n",
    "                    p = -delta * g / np.linalg.norm(g)\n",
    "                else:\n",
    "                    p = delta * p_newton / np.linalg.norm(p_newton) #USAR paso Cauchy truncado al borde de la REgion\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Hessiano Singular => usar dirección de descenso más pronunciado\n",
    "            p = -delta * g / np.linalg.norm(g)\n",
    "\n",
    "        # 3- Evaluar calidad del Paso    \n",
    "        f_actual = f(x)\n",
    "        # valor real funcion en el nuevo paso\n",
    "        f_new = f(x + p)\n",
    "\n",
    "\n",
    "        # Aproximacion Taylor 2do Orden (Modelo Cuadrático)\n",
    "        m_new = f_actual + np.dot(g, p) + 0.5*np.dot(p, np.dot(B, p))\n",
    "        # Razon de Reducción: reducción real / reduccion predicha\n",
    "        rho = (f_actual - f_new) / (f_actual - m_new + 1e-12)\n",
    "        \n",
    "        # 4- Ajustar radio region de confianza\n",
    "        if rho < 0.25:\n",
    "            delta *= 0.25 # Reducir la region de cofianza\n",
    "        elif rho > 0.75:\n",
    "            delta = min(2*delta, 10) # expandir region de confianza\n",
    "        \n",
    "        # 5- Decición de aceptar o no el PASO\n",
    "        if rho > eta:\n",
    "            x = x + p # PASO ACEPTADO => moverse al nuevo punto\n",
    "            history.append(x.copy())\n",
    "        # PASO MUY GRANDE => PARAR    \n",
    "        if np.linalg.norm(p) < tol:\n",
    "            break\n",
    "    return x, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d99e9b",
   "metadata": {},
   "source": [
    "Desarrollo Algoritmo Regulación Adaptativa Cúbica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método ARC (Regularización Adaptativa Cúbica)\n",
    "def arc_method(x0, grad_f, hess_f, sigma0=1.0, tol=1e-6, max_iter=1000):\n",
    "    \n",
    "    # x0: punto inicial\n",
    "    # grad_f: función que calcula el gradiente\n",
    "    # hess_f: función que calcula el Hessiano  \n",
    "    # sigma0: parámetro de regularización inicial\n",
    "    # tol: tolerancia para criterio de parada\n",
    "    # max_iter: número máximo de iteraciones\n",
    "\n",
    "    x = np.array(x0, dtype=float)\n",
    "    sigma = sigma0 # Parametro Regulacion Cubica\n",
    "    history = [x.copy()] # Hiatorial puntos\n",
    "\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # 1- Calcular gradiente & Hessiano en el punto Actual\n",
    "        g = grad_f(x)\n",
    "        B = hess_f(x)\n",
    "\n",
    "        # Verificar si el gradiente es suficientemente pequeño\n",
    "        if np.linalg.norm(g) < tol:\n",
    "            break\n",
    "        # 2- Resolver Subproblema regularizador Cubico\n",
    "        try:\n",
    "            # Calcular paso => (B + sigma*I)p = -g\n",
    "            p = -np.linalg.solve(B + sigma*np.eye(len(x)), g)\n",
    "        except np.linalg.LinAlgError:\n",
    "            p = -g / (np.linalg.norm(g) + 1e-12) # Problemas Numericos => usar direccion descenso mas pronunciado\n",
    "        \n",
    "        # 3- Evaluar calidad del paso\n",
    "        f_actual = f(x)\n",
    "        f_new = f(x + p)  # valor real de la funcion en el nuevo punto \n",
    "        p_norm = np.linalg.norm(p)\n",
    "\n",
    "        # Taylor 2do orden + térmico cúbico (Modelo Cúbico)\n",
    "        m_new = f_actual + np.dot(g, p) + 0.5*np.dot(p, np.dot(B, p)) + (sigma/3)*p_norm**3\n",
    "\n",
    "        # Calcular razón de reducción => reducción real / reducción predicha\n",
    "        rho = (f_actual - f_new) / (f_actual - m_new + 1e-12)\n",
    "\n",
    "        # 4- Ajustar parametro regularizacion\n",
    "        if rho < 0.25:\n",
    "            sigma *= 2 # aumentar regularizacion => pasos más conservadores\n",
    "        elif rho > 0.75:\n",
    "            sigma = max(sigma/2, 1e-8) # disminuir regularizacion\n",
    "        \n",
    "        # 5- Decision acpetar o NO el paso-\n",
    "        if rho > 1e-4:\n",
    "            # Paso aceptado => moverse al nuevo punto\n",
    "            x = x + p\n",
    "            history.append(x.copy())\n",
    "\n",
    "        # paso muy pequeño => PARAR     \n",
    "        if np.linalg.norm(p) < tol:\n",
    "            break\n",
    "    return x, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8e1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución Métodos\n",
    "np.random.seed(42)\n",
    "x0 = np.random.uniform(-2, 2, size=2)\n",
    "print(\"Punto inicial:\", x0)\n",
    "print(\"f(x0) =\", f(x0))\n",
    "\n",
    "x_tr, hist_tr = trust_region_method(x0, grad_f, hess_f)\n",
    "x_arc, hist_arc = arc_method(x0, grad_f, hess_f)\n",
    "\n",
    "print(\"Óptimo Región de Confianza:\", x_tr, \"f(x) =\", f(x_tr))\n",
    "print(\"Óptimo ARC:\", x_arc, \"f(x) =\", f(x_arc))\n",
    "\n",
    "\n",
    "# Crear malla vectorizada\n",
    "x_range = np.linspace(-2, 2, 200)\n",
    "y_range = np.linspace(-2, 2, 200)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "Z = np.vectorize(lambda x, y: f([x, y]))(X, Y)\n",
    "\n",
    "# Historiales como arrays\n",
    "hist_tr_arr = np.array(hist_tr)\n",
    "hist_arc_arr = np.array(hist_arc)\n",
    "f_tr = np.array([f(x) for x in hist_tr])\n",
    "f_arc = np.array([f(x) for x in hist_arc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAFICOS 2D - Primero solo los gráficos\n",
    "\n",
    "# Crear figura solo para gráficos\n",
    "fig_graphs = plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 1. Vista 2D \n",
    "ax1 = fig_graphs.add_subplot(121)\n",
    "# Contornos con más niveles y colormap invertido\n",
    "contour = ax1.contour(X, Y, Z, 30, cmap=cm.coolwarm_r, alpha=0.7)\n",
    "ax1.clabel(contour, inline=True, fontsize=8)\n",
    "\n",
    "# Trayectorias 2D\n",
    "ax1.plot(hist_tr_arr[:,0], hist_tr_arr[:,1], 'o-', color='red', linewidth=2, \n",
    "         markersize=6, markerfacecolor='darkred', markeredgecolor='black', \n",
    "         markeredgewidth=0.5, label='Región de Confianza')\n",
    "ax1.plot(hist_arc_arr[:,0], hist_arc_arr[:,1], 's-', color='blue', linewidth=2, \n",
    "         markersize=6, markerfacecolor='darkblue', markeredgecolor='black', \n",
    "         markeredgewidth=0.5, label='ARC')\n",
    "\n",
    "# Puntos importantes\n",
    "ax1.scatter([x0[0]], [x0[1]], color='green', s=150, marker='*', \n",
    "           edgecolor='black', linewidth=1, label='Punto Inicial', zorder=5)\n",
    "ax1.scatter([x_tr[0]], [x_tr[1]], color='red', s=150, marker='*', \n",
    "           edgecolor='black', linewidth=1, label='Óptimo TR', zorder=5)\n",
    "ax1.scatter([x_arc[0]], [x_arc[1]], color='blue', s=150, marker='*', \n",
    "           edgecolor='black', linewidth=1, label='Óptimo ARC', zorder=5)\n",
    "\n",
    "ax1.set_xlabel('x', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('y', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Trayectorias de Optimización', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.7)\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "# 2. Gráfico de convergencia\n",
    "ax2 = fig_graphs.add_subplot(122)\n",
    "f_min = min(f_tr[-1], f_arc[-1])\n",
    "\n",
    "ax2.semilogy(np.arange(len(f_tr)), f_tr - f_min, 'o-', color='red', linewidth=2.5,\n",
    "             markersize=6, markerfacecolor='darkred', markeredgecolor='black',\n",
    "             markeredgewidth=0.5, label='Región de Confianza')\n",
    "ax2.semilogy(np.arange(len(f_arc)), f_arc - f_min, 's-', color='blue', linewidth=2.5,\n",
    "             markersize=6, markerfacecolor='darkblue', markeredgecolor='black',\n",
    "             markeredgewidth=0.5, label='ARC')\n",
    "\n",
    "ax2.set_xlabel('Iteración', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('f(x) - f*', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Convergencia de la Función Objetivo', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.7)\n",
    "\n",
    "# Ajustar layout y mostrar gráficos\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TABLA VISUAL - Figura separada\n",
    "fig_table = plt.figure(figsize=(10, 4))\n",
    "ax_table = fig_table.add_subplot(111)\n",
    "ax_table.axis('tight')\n",
    "ax_table.axis('off')\n",
    "\n",
    "# Calcular métricas adicionales\n",
    "norm_grad_tr = np.linalg.norm(grad_f(x_tr))\n",
    "norm_grad_arc = np.linalg.norm(grad_f(x_arc))\n",
    "path_length_tr = np.sum(np.linalg.norm(np.diff(hist_tr_arr, axis=0), axis=1))\n",
    "path_length_arc = np.sum(np.linalg.norm(np.diff(hist_arc_arr, axis=0), axis=1))\n",
    "\n",
    "# Datos para la tabla\n",
    "table_data = [\n",
    "    ['Métrica', 'Región de Confianza', 'ARC'],\n",
    "    ['Iteraciones', f'{len(hist_tr)}', f'{len(hist_arc)}'],\n",
    "    ['f(x) final', f'{f_tr[-1]:.6e}', f'{f_arc[-1]:.6e}'],\n",
    "    ['||∇f(x)|| final', f'{norm_grad_tr:.2e}', f'{norm_grad_arc:.2e}'],\n",
    "    ['Longitud trayectoria', f'{path_length_tr:.4f}', f'{path_length_arc:.4f}'],\n",
    "    ['Punto óptimo', f'({x_tr[0]:.4f}, {x_tr[1]:.4f})', f'({x_arc[0]:.4f}, {x_arc[1]:.4f})']\n",
    "]\n",
    "\n",
    "# Crear tabla\n",
    "table = ax_table.table(cellText=table_data, \n",
    "                      cellLoc='center', \n",
    "                      loc='center',\n",
    "                      colWidths=[0.3, 0.35, 0.35])\n",
    "\n",
    "# Estilo de la tabla\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 1.8)\n",
    "\n",
    "# Colores y estilo de celdas\n",
    "for i, key in enumerate(table.get_celld().keys()):\n",
    "    cell = table.get_celld()[key]\n",
    "    if key[0] == 0:  # Encabezado\n",
    "        cell.set_facecolor('#4B8BBE')\n",
    "        cell.set_text_props(weight='bold', color='white', size=12)\n",
    "    elif key[0] % 2 == 1:  # Filas impares\n",
    "        cell.set_facecolor('#F9F9F9')\n",
    "    else:  # Filas pares\n",
    "        cell.set_facecolor('#FFFFFF')\n",
    "    \n",
    "    # Negrita para la primera columna (nombres de métricas)\n",
    "    if key[1] == 0 and key[0] > 0:\n",
    "        cell.set_text_props(weight='bold')\n",
    "\n",
    "# Título de la tabla\n",
    "ax_table.set_title('COMPARACIÓN DE ALGORITMOS DE OPTIMIZACIÓN', \n",
    "                  fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Ajustar layout y mostrar tabla\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Información adicional de convergencia\n",
    "print(f\"\\n--- Estadísticas de Convergencia ---\")\n",
    "print(f\"Punto inicial: ({x0[0]:.4f}, {x0[1]:.4f}) | f(x0) = {f(x0):.6e}\")\n",
    "print(f\"Región de Confianza: {len(hist_tr)} iteraciones, f final = {f_tr[-1]:.6e}\")\n",
    "print(f\"ARC: {len(hist_arc)} iteraciones, f final = {f_arc[-1]:.6e}\")\n",
    "print(f\"Diferencia entre métodos: {abs(f_tr[-1] - f_arc[-1]):.2e}\")\n",
    "\n",
    "# Análisis comparativo\n",
    "print(f\"\\n*** Análisis Comparativo ***\")\n",
    "if abs(f_tr[-1] - f_arc[-1]) < 1e-8:\n",
    "    print(\"Ambos métodos convergen esencialmente al mismo valor óptimo\")\n",
    "elif f_tr[-1] < f_arc[-1]:\n",
    "    print(\"Región de Confianza encuentra una solución ligeramente mejor\")\n",
    "else:\n",
    "    print(\"ARC encuentra una solución ligeramente mejor\")\n",
    "\n",
    "if len(hist_tr) < len(hist_arc):\n",
    "    print(f\"Región de Confianza es {len(hist_arc)/len(hist_tr):.1f}x más rápido\")\n",
    "else:\n",
    "    print(f\"ARC es {len(hist_tr)/len(hist_arc):.1f}x más rápido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900fbc17",
   "metadata": {},
   "source": [
    "Resultados Obtenidos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a591de",
   "metadata": {},
   "source": [
    "![Texto alternativo](TrayectoriaOpt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86edd48",
   "metadata": {},
   "source": [
    "![Texto alternativo](COnvergenciaFO.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4119a",
   "metadata": {},
   "source": [
    "![Texto alternativo](TablaComparativa.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
